---
# =============================================================================
# Flask App Server Deployment — pinned to Intel (amd64) node
#
# Placement strategy:
#   nodeAffinity: requiredDuringScheduling — MUST run on amd64 (Intel)
#                 workload-type=appserver  (set by 01-node-labels-taints.sh)
#
# Image: built by OCP S2I BuildConfig (04-appserver-build.yaml)
#        stored in internal ImageStream: hetero-demo-app:latest
#        NO docker.io images required.
#
# Database: Direct PostgreSQL deployment (03-postgres-direct.yaml) on Power (ppc64le)
#   Primary service: hetero-postgres-service.hetero-demo.svc.cluster.local:5432
#   Credentials:     Secret hetero-postgres-secret
# =============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flask-appserver
  namespace: hetero-demo
  labels:
    app: flask-appserver
    tier: appserver
    arch: amd64
    app.kubernetes.io/part-of: hetero-hcp-demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: flask-appserver
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: flask-appserver
        tier: appserver
        arch: amd64
    spec:
      # -----------------------------------------------------------------------
      # Hard node affinity: MUST run on amd64 (Intel) node
      # -----------------------------------------------------------------------
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: kubernetes.io/arch
                    operator: In
                    values:
                      - amd64
                  - key: workload-type
                    operator: In
                    values:
                      - appserver
      # -----------------------------------------------------------------------
      # Tolerations — add these if you enabled taints in 01-node-labels-taints.sh
      # -----------------------------------------------------------------------
      # tolerations:
      #   - key: dedicated
      #     operator: Equal
      #     value: appserver
      #     effect: NoSchedule
      # -----------------------------------------------------------------------
      initContainers:
        # Wait for the PostgreSQL service to be ready.
        # Uses the OCP internal cli image — already mirrored in the internal OCP registry.
        - name: wait-for-postgres
          image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
          command:
            - bash
            - -c
            - |
              echo "Waiting for hetero-postgres-service:5432 to be ready..."
              until bash -c "echo > /dev/tcp/hetero-postgres-service/5432" 2>/dev/null; do
                echo "Postgres not ready yet, sleeping 5s..."
                sleep 5
              done
              echo "Postgres is ready!"
      containers:
        - name: flask-appserver
          # Image built by OCP S2I BuildConfig (04-appserver-build.yaml)
          # Stored in the internal OCP ImageStream — no docker.io pull needed.
          image: image-registry.openshift-image-registry.svc:5000/hetero-demo/hetero-demo-app:latest
          imagePullPolicy: Always
          ports:
            - containerPort: 8080
              name: http
          env:
            # DATABASE_URL from the direct postgres secret (hetero-postgres-secret)
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: hetero-postgres-secret
                  key: uri
            # Expose node and pod name inside the app for the /arch endpoint
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          resources:
            requests:
              cpu: "250m"
              memory: "256Mi"
            limits:
              cpu: "1"
              memory: "512Mi"
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 20
            periodSeconds: 10
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /ready
              port: 8080
            initialDelaySeconds: 10
            periodSeconds: 5
            failureThreshold: 3
          startupProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 10
            periodSeconds: 5
            failureThreshold: 12
      terminationGracePeriodSeconds: 30
      serviceAccountName: default